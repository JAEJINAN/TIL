```bash
.
└── Deep Learning/
    ├── Math, Knowledged/
    │   ├── Calculus
    │   ├── Linear Algebra
    │   ├── Statistics
    │   ├── Optimization
    │   ├── Information Theory
    │   └── etc
    ├── programming/
    │   ├── python/
    │   │   ├── Tensorflow
    │   │   └── Pytorch
    │   ├── R
    │   ├── Javascript
    │   └── etc
    └── Neural Network/
        ├── Perceptron
        ├── forward propagation/
        │   ├── data, weight, bias, weigted sum
        │   ├── activation function
        │   ├── loss function
        │   └── initialization of weights/
        │       ├── He initialization
        │       └── etc
        ├── backward propagation/
        │   └── gradient descent/
        │       ├── Batch
        │       ├── SGD
        │       ├── Mini Batch
        │       ├── Momentum
        │       ├── AdaGrad
        │       ├── Adam
        │       └── etc
        ├── Overfitting, Underfitting/
        │   ├── normalization
        │   ├── batch normalization
        │   └── increse # of data
        └── hyperparameter tuning/
            ├── fine tuning
            └── transfer learning
```

