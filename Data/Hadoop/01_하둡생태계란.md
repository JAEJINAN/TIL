# Hadoop 구성 요소

## Core Hadoop System

<img src="C:\Users\Jay\AppData\Roaming\Typora\typora-user-images\image-20220612231136613.png" alt="image-20220612231136613" style="zoom:70%;" />



- HDFS (Hadoop Distribute File System)
  - 빅데이터를 클러스터의 컴퓨터들에 분산 저장하는 시스템
  - 여러 클러스터들의 하드 드라이브를 하나의 거대한 파일 시스템으로 사용
  - 데이터의 복사본까지 만들어 백업까지 함
- YARN (Yet Another Resource Negotiator)
  - HDFS가 하둡의 데이터 저장부분이면 YARN은 데이터 처리 부분을 담당
  - 클러스터들의 리소스를 관리하는 시스템
  - 누가 작업을 언제 실행하고, 어떤 노드가 추가 작업 할 수 있고, 권한 등을 결정
- MapReduce
  - Mapper와 Reducer로 구성
  - Mapper는 클러스터에 분산되어있는 데이터를 효율적으로 동시 변형시킬 수 있음
  - Reducer는 그 데이터들을 집계함
- Pig
  - 고수준 API (MapReduce 위에 존재)
  - SQL과 비슷한 스크립트를 작성해 쿼리하고 복잡한 답을 구할 수 있음
  - Java나 Python 코드 필요없음
  - Pig는 작성된 스크립트를 번역해 MapReduce가 읽을 수 있게 해주고, MapReduce는 YARN과 HDFS에게 데이터를 처리해서 가져오라 시킴
- Hive
  - Pig와 비슷함.
  - 더 SQL에 가까움. Hive는 SQL 쿼리를 받아 SQL DB처럼 분산 데이터를 처리함
  - shell client나 ODBS 등을 통해 DB에 접속할 수 있고, 하둡 클러스터 내 데이터가 관계형이 아니어도 SQL로 쿼리가 가능하다.
- Apache Ambari
  - 클러스터 전체를 보여줌. 클러스터에서 어떤 시스템을 사용하는지, 리소스는 얼마나 먹는지 등을 시각화해주고 Hive나 Pig를 실행하거나 DB를 불러올 수 있는 화면이 존재.
  - 비슷한 걸론 MapR 등이 있다.

- Mesos
  - 엄밀히 Hadoop의 일부는 아니나 YARN의 대안 정도로 보면 된다. YARN과 같은 Resource Negotiator
  - 클러스터의 리소스를 관리하는 시스템
  - Mesos와 YARN을 같이 사용할 수도 있다.
- Spark
  - MapReduce와 동일 선상에 존재하는 시스템
  - Python, Java, Scala 언어 지원, 프로그래밍을 통해 접근 (scala 추천함)
  - 빠르고, 효율적이며 안정적이다. 
  - 다양한 기능 지원
    - Spark ML
    - Spark Streaming 등
- TEZ
  - Spark와 비슷한 기술을 많이 사용, 방향성 비사이클 그래프를 사용(DAG; Directed Acyclic Graph)
  - MapReduce 작업을 할때 유리(쿼리에 더 효율적인 계획생성)
  - 보통 Hive와 함께 쓰여 성능을 가속함
- HBASE
  - 클러스터의 데이터를 트랜잭션 플랫폼으로 노출하는 역할을 하며 NoSQL 데이터베이스임
  - 단위 시간당 실행되는 트랜잭션 수가 큰 아주 빠른 데이터베이스
  - OLTP 트랜잭션하는데 적합(Online Transaction Processing)
- Apache STORM
  - 스트리밍 데이터를 처리
  - 센서, 웝로그 등의 데이터를 스트리밍한다면 STORM이나 Spark Streaming을 사용할 수 있음
  - 실시간 처리를 위해 개발됨(배치처리X)

- OOZIE
  - 클러스터의 작업을 스케쥴링함
  - 일정에 따라 작업을 순차적으로 진행할 수 있도록 스케쥴링한다.
- Zookeeper
  - 클러스터의 모든 것을 조직화하는 기술
  - 노드가 살아있는지 추적할 수 있고, 여러 애플리케이션이 사용하는 클러스터의 공유 상태를 안정적으로 확인함
  - 많은 애플리케이션이 Zookeeper에 의존함
  - 어떤 노드가 죽더라도 일관성있고 안정적인 성능을 온 클러스터에 걸쳐 유지할 수 있게해줌
- 데이터 수집
  - Sqoop
    - RDB와 Hadoop간 데이터 입출력을 가능하게 해줌 (일종의 연결 장치)
    - ODBC나 JDBC로 소통가능한 데이터를 Sqoop을 통해 HDFS파일로 변형할 수도 있음
  - FLUME
    - 대규모 웹로그를 안정적으로 클러스터에 불러올 수 있게 해줌
    - 실시간으로 웹 서버의 웹로그를 감시하고 클러스터에 게시해 STORM이나 Spark Streaming을 사용해 처리
  - Kafka
    - 데이터 수집
    - 클러스터에서 모든 종류의 데이터를 수집해 Hadoop 클러스터로 보냄



## Query Engines

<img src="C:\Users\Jay\AppData\Roaming\Typora\typora-user-images\image-20220612233405620.png" alt="image-20220612233405620" style="zoom:100%;" align="Left"/>

- Apache DRILL
  - 다양한 NoSQL DB에 SQL 쿼리를 작성해 사용할 수 있도록 해줌
- HUE
  - Hive, HBase에 잘 작동하는 쿼리를 대화형으로 생성할 수 있음
- Apache PHOENIX
  - Apache DRILL 과 비슷
  - 또한 ACID를 보장해줌 (Atomicity, Consistency, Isolation, Durability)
  - OLTP 제공
- Presto
  - 위에와 비슷
- Zeppelin
  - 클러스터와의 상호작용과 사용자 인터페이스를 notebook 형태로 만듦















