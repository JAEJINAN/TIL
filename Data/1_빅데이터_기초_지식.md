# 빅데이터 기초 지식

## 1.1 빅데이터의 정착

분산 시스템 기술의 발전으로 데이터 처리 속도가 급속도로 빨라졌다. 빅데이터라는 말이 나온지는 오래되었지만 정확히 빅데이터를 어떻게 사용해야 할지, 빅데이터 기술을 안심하고 쓸 수 있는지는 고려해봐야할 점이다.

빅데이터 취급의 어려운 점은 크게 두 가지다.

- 데이터 분석방법
- 데이터 처리에 드는 노동과 비용



### 빅데이터 기술의 요구

- Hadoop과 NoSQL의 대두

  <img src="C:\Users\Jay\Desktop\New_git\TIL\Data\src\IMG_1378.jpg" alt="IMG_1378" style="zoom: 30%;" align="Left"/>



웹 서버 등에서 생성된 데이터는 RDB나 NoSQL 등에 저장된 후 Hadoop으로 모이고, 거기서 대규모 데이터 처리가 실행된다.

데이터의 양이 기하급수적으로 증가하면서 기존의 RDB에서 수용하기가 불가능해졌다. 여기서 Hadoop과 NoSQL은 다음을 위해 태어났다.



#### Hadoop

방대한 데이터를 저장해둘 스토리지와 데이터를 순차적으로 처리할 구조의 필요성이 생겼다. 한 대의 스토리지를 늘릴 수도 있지만 이는 엄청난 비용을 필요로 한다. 그러기에 수백, 수천대 이상의 컴퓨터를 묶어서 데이터를 관리하고자 하는 수요가 생겼고, 이를 관리하는 것이 Hadoop 프레임워크다.

구글에서 개발된 분산 처리 프레임워크인 `MapReduce`를 참고하여 제작되었다. `MapReduce`는 자바 프로그래밍 기반으로 동작하는데, 그렇기에 누구나 간단히 사용하지 못해왔다.

SQL과 같은 쿼리 언어로 Hadoop을 실행하기 위한 요구로 인해 `Hive`가 2009년에 출시되었다. 이로 인해 프로그래밍 없이 데이터를 집계할 수 있게 되었고 Hadoop을 이용한 분산 시스템의 혜택을 받을 수 있게 되었다.



#### NoSQL Database

빈번한 읽기/쓰기 및 분산 처리가 강점

다양한 종류의 NoSQL이 존재한다.

- key-value store (키-밸류 페어)
- document store (JSON 기반)
- wide-column store (여러 키를 사용)
- 등등

보통 RDB보다 고속의 읽기, 쓰기가 가능하고 분산 처리에 뛰어나다는 특징을 갖추고 있다.



#### Hadoop + NoSQL

현실적인 비용으로 대규모 데이터 처리 실현



### 분산 시스템의 비즈니스 이용 개척

일부 기업들은 이전부터 데이터 분석을 기반으로 하는 `데이터 웨어하우스(DW)`를 도입했다.

분산 시스템의 발전에 따라 Hadoop의 사용자가 많이 증가했다. 빅데이터 덕이다.

전통적인 DW로도 대량의 데이터 처리를 할 수 있지만, Hadoop이 우수하다.

다만, 안정적인 성능을 위한 HW, SW가 통합된 통합 장비(appliance)를 DW는 제공했다. (Hadoop의 불리한 점)

그렇기에 가속도적으로 늘어나는 데이터의 처리는 Hadoop을 쓰고, 비교적 작은 데이터, 또는 중요한 데이터만을 DW에 넣는 방식으로 사용하게 되었다.

<img src="C:\Users\Jay\Desktop\New_git\TIL\Data\src\IMG_1379.jpg" alt="IMG_1379" style="zoom:30%;" align="Left"/>





### 데이터 디스커버리의 기초지식

셀프서비스용 BI 도구

빅데이터 기술의 등장과 함께 DW에 저장된 데이터를 시각화하려는 방법으로 `데이터 디스커버리(data discovery)`가 인기를 끌게 되었다. 대화형으로 데이터를 시각화하여 가치 있는 정보를 찾으려고 하는 프로세스를 뜻한다.

`BI 도구`(business intelligence tool)가 데이터 디스커버리를 돕는다.



효율성과 편리성을 위해서 기술은 계속되어 발전되고 있다. `Apache Spark`와 같은 새로운 분산 시스템도 등장하고 MapReduce보다 효율적으로 데이터를 처리할 수 있게 만들고 있다.

배치 처리뿐만 아니라 실시간 데이터 처리를 위한 시스템도 만들어 지고 있다.



 ## 1.2 빅데이터 시대의 데이터 분석 기반

빅데이터 기술이란 분산 시스템을 활용하면서 데이터를 순차적으로 가공해 나가는 일련의 구조이다.



### 빅데이터의 기술

#### 데이터 파이프라인

> 데이터 수집에서 워크플로 관리까지

일반적으로 차례대로 전달해나가는 데이터로 구성된 시스템을 `데이터 파이프라인(data pipeline)`라고 한다. 목적에 따라 복잡할 수도 있고 아닐수도 있고, 다양한 조합을 통해 파이프라인 구성이 가능하다.



#### 데이터 수집

> 벌크 형과 스트리밍 형의 데이터 전송

데이터 파이프라인은 데이터를 모으는 부분부터 시작이다. 다양한 데이터가 다양한 곳에서 모인다. 이벤트, 로그, 이미지/텍스트/음성, 센서 데이터 등이 있다. 또한 데이터를 전송하는 방법은 데이터마다 다르다.

`데이터 전송(data transfer)`의 방법은 크게 2가지다.

- 벌크(bulk) 형
  - 이미 어딘가 존재하는 데이터를 정리해 추출하는 방법
  - 데이터베이스와 파일 서버 등에서 정기적으로 데이터를 수집
- 스트리밍(streaming) 형
  - 계속적으로 생성되는 데이터를 보내는 방법으로 센서 데이터 수집이 여기에 속한다.

<img src="C:\Users\Jay\Desktop\New_git\TIL\Data\src\IMG_1380.jpg" alt="IMG_1380" style="zoom:33%;" align="Left"/>



#### 스트림 처리와 배치 처리

기존 시스템의 경우 DW에서 다루는 데이터는 주로 벌크형 방식을 써왔다. 빅데이터 시대가 도래하면서 스트리밍형 방식이 주가 되었다.

스트리밍 형 방법으로 받은 데이터를 실시간으로 처리하는 것을 `스트림 처리(stream processing)`이라고 한다.

예를 들어 시계열 데이터(time-series) 처리가 여기에 속한다.



한편, 스트림 처리는 장기적인 데이터 분석에는 적합하지 않은 문제가 있다.

장기적인 데이터 분석을 위해서는 보다 대량의 데이터를 저장하고 처리하는 데 적합한 분산 시스템이 좋다. 여기에 필요한 것은 어느 정도 정리된 데이터를 효율적으로 가공하기 위한 `배치 처리(batch processing)` 구조다.



#### 분산 스토리지

> 객체 스토리지, NoSQL 데이터베이스

수집된 데이터는 `분산 스토리지(distribute storage)`에 저장된다. 

> 여기서 말하는 분산 스토리지란 여러 컴퓨터와 디스크로부터 구성된 스토리지 시스템을 말한다. 

데이터를 저장하는 방법에는 몇가지 선택이 있다. 대표적인 것이 `객체 스토리지(object storage)`로 한 덩어리로 모인 데이터에 이름을 부여해서 파일로 저장한다. (대표적으로 Amazon S3이 유명)



NoSQL DB도 분산 스토리지로 사용할 수 있다. 많은 데이터를 읽고 쓰려면 NoSQL이 성능면에서 우수하다. 단, 확장성이 높은 DB를 선택해야한다.



#### 분산 데이터 처리

> 쿼리 엔진, ETL 프로세스

분산 스토리지에 저장된 데이터를 처리하기 위해서는 `분산 데이터 처리(distribute data processing)`프레임워크가 필요하다.

예) MapReduce 사용 (데이터양과 처리의 내용에 따라 많은 컴퓨터 자원 필요)

분산 데이터 처리의 주 역할 : 나중에 분석이 쉽도록 데이터를 가공해 그 결과를 외부 데이터베이스에 저장하는 것



빅데이터를 SQL로 집계할 때 사용 가능한 방법 2가지

- 쿼리 엔진(query engine) 도입
  - 분산 스토리지 상의 데이터를 SQL로 집계하기 위해 쿼리 엔진을 도입
  - Hive가 한 예
- 외부 데이터 웨어하우스 제품 이용
  - 분산 스토리에서 추출한 데이터를 DW에 적합한 형식으로 변환해 로드
  - 이를 `ETL (extract-transform-load)` 프로세스라고 한다.



#### 워크플로 관리

전체 데이터 파이프라인의 동작을 관리하기 위해 `워크플로 관리`(workflow management) 기술을 사용

스케줄에 맞게 정해진 시간에 배치 처리를 하고, 오류 발생시 관리자에게 통지한다.

데이터 파이프라인이 복잡해짐에 따라 한곳에서 제어 및 관리를 안하면 파악이 어려워진다. 빅데이터 처리에서 장애는 필수불가결하기 때문에 장애(오류) 발생시 처리와 다시 처리하기 위한 기능을 넣어둬야 한다.





### 데이터 웨어하우스와 데이터 마트

> 데이터 파이프라인 기본형

<img src="C:\Users\Jay\Desktop\New_git\TIL\Data\src\IMG_1383.jpg" alt="IMG_1383" style="zoom:40%;" align="Left"/>

DW, DM 모두 SQL로 데이터를 집계한다. 테이블 설계를 정한 후에 데이터를 투입한다. BI 도구를 쓸 경우 미리 시각화에 적합한 형태로 테이블을 준비해야 한다. DW를 중심으로 파이프라인을 구축하면 테이블 설계와 ETL 프로세스가 중요하다.



1. 데이터 웨어하우스

	- 웹 서버나 업무 시스템에서 이용되는 일반적인 RDB와는 달리 `대량의 데이터를 장기 보존`에 최적화됨
	- 정리된 데이터를 한 번에 전송하는 것은 뛰어나지만, 소량의 데이터를 자주 쓰고 읽는데는 적합하지 않음
	- 업무 시스템에서 꺼낸 데이터를 하루가 끝날 때 정리하여 쓰고, 이것을 야간 시간대에 집계해서 보고서를 작성함.
	- RDB나 로그 등을 저장하는 파일 서버를 `데이터 소스`(data source) 라고 함
	- 데이터 소스에 보존된 데이터를 `로우 데이터`(raw data, 원시데이터)라하고 이를 추출, 가공, DW에 저장하는 흐름이 바로 `ETL 프로세스`이다.
	- DW 구축에는 ETL tools라는 전용 소프트웨어를 주로 사용



2. 데이터 마트
   - DW는 업무에 있어 중요한 데이터 처리에 사용되기 때문에 아무때나 함부로 사용하면 시스템에 과부하를 줄 수 있다.
   - 데이터 분석과 같은 목적에 사용하는 경우 DW에서 필요한 데이터만 추출해 `데이터 마트`를 구축한다.
   - BI 도구와 결합해 데이터를 시각화하는데도 사용된다.



### 데이터 레이크

> 데이터를 그대로 축적

데이터 양이 방대해지면서 ETL 프로세스 자체가 복잡해지고 어려워졌다. 모든 데이터가 DW를 가정해서 만들어지지는 않는다.

비정형데이터(텍스트, 바이너리 등)은 그대로 DW에 넣을 수도 없다.

빅데이터는 우선 데이터가 있고, 나중에 테이블을 설계하는 것이다.

그렇기에 모든 데이터를 일단 한곳에 넣어두고 필요에 의해 가공하는 구조가 필요하게 되었다. 모든 데이터를 넣을 곳이 필요하게 되었는데 데이터를 축적하는 호수의 개념에서 그 장소를 `데이터 레이크`(data lake)라고 한다.

구체적으로는 임의의 데이터를 저장할 수 있는 분산 스토리직가 데이터 레이크로 이용된다.

데이터 형식은 자유! , 근데 대부분 `CSV`나 `JSON` 형식으로 저장된다.



<img src="C:\Users\Jay\Desktop\New_git\TIL\Data\src\IMG_1384.jpg" alt="IMG_1384" style="zoom:45%;" align="Left"/>



#### 데이터 웨어하우스 vs 데이터 레이크

원시데이터를 가공해서 넣냐, 그냥 넣냐의 차이



#### 데이터 레이크와 데이터 마트

> 필요한 데이터는 데이터 마트에 정리

데이터 레이크는 단순한 스토리지이다. 바로 데이터 가공을 할 수는 없다.

그래서 사용하는게 MapReduce같은 분산 데이터 처리 기술이다.

데이터 분석에 필요한 데이터를 가공, 집계하고 이를 데이터 마트로 추출한 후에 데이터 웨어하우스의 경우처럼 데이터 분석을 진행할 수 있다.



### 데이터 분석 기반을 단계적으로 발전시키기

> 팀과 역할 분담, 스몰 스타트와 확장

데이터 분석에 필요한 기술은 폭 넓고 다양하다. 그래서 개인이 할 수 없을 정도. 그래서 팀 분담으로 작업한다.

두 직무에 요구되는 지식뿐만 아니라 사용 도구도 나뉜다.

- 데이터 엔지니어(data engineer) : 시스템의 구축 및 운용, 자동화 등을 담당

- 데이터 분석가(data analyst) : 데이터에서 가치 있는 정보를 추출



 

