# 01. 인공신경망

인공 신경망의 기본 구조는 *Frank Rosenblatt*가 고안한 **퍼셉트론(perceptron)**이라는 선형 분류기다.



## 퍼셉트론

**Perceptron**
다수의 입력(신호)를 받아 하나의 출력을 내보내는 단순한 분류기
Hidden Layer가 없이 Single Layer로 구성되어 있다.

<img src="C:\Users\jay\Desktop\code\ML\딥러닝기본이론\perceptron.jpg" alt="perceptron" style="zoom:60%;" align="Left"/> 















다음의 이미지는 단순히 2개의 입력을 받아 하나를 전달하는 퍼셉트론 구조다.





## 논리게이트

입력 두 개($x_1, x_2$)가 있을 때 컴퓨터가 논리적으로 인식하는 방법에 대해 알아보자.



### AND 게이트

AND 게이트는 모든 입력이 1 (true)일 때 1을 출력한다.

| $x_1$ | $x_2$ | $y$  |
| ----- | ----- | ---- |
| 0     | 0     | 0    |
| 1     | 0     | 0    |
| 0     | 1     | 0    |
| 1     | 1     | 1    |

 

### NAND 게이트

AND 게이트의 반대 개념이다. 입력 모두가 1일 때 0을 출력하고 나머진 1을 출력한다.

| $x_1$ | $x_2$ | $y$  |
| ----- | ----- | ---- |
| 0     | 0     | 1    |
| 1     | 0     | 1    |
| 0     | 1     | 1    |
| 1     | 1     | 0    |



### OR 게이트

OR 게이트는 입력 중 하나만 1, 또는 모두 1일 때만 1을 출력한다.

| $x_1$ | $x_2$ | $y$  |
| ----- | ----- | ---- |
| 0     | 0     | 0    |
| 1     | 0     | 1    |
| 0     | 1     | 1    |
| 1     | 1     | 1    |



### XOR 게이트

XOR 게이트는 배타적 논리합이라는 용어로도 쓰인다.
입력 중 한개만 1일 때 1을 출력한다.

| $x_1$ | $x_2$ | $y$  |
| ----- | ----- | ---- |
| 0     | 0     | 0    |
| 1     | 0     | 1    |
| 0     | 1     | 1    |
| 1     | 1     | 0    |



## 다층 퍼셉트론

기존의 한 개의 층만 갖는 퍼셉트론으로 논리게이트를 설명하다 보니 XOR 게이트의 문제는 풀 수가 없었다. (선형으로는 XOR을 나눌 수가 없었기 때문에)

<img src="C:\Users\jay\Desktop\code\ML\딥러닝기본이론\3.PNG" alt="3" style="zoom:75%;" align="Left"/>

직선을 어떻게 긋던 XOR을 풀수가 없다. (비선형으로는 가능)



XOR문제를 풀기위해 층을 한개가 아닌 여러개를 쌓으면 어떨까?

두 개의 층을 생각 해보자.

<img src="C:\Users\jay\Desktop\code\ML\딥러닝기본이론\4_0.png" alt="4_0" style="zoom:48%;" align="Left"/>

첫 번째 층에 NAND, OR 게이트를 적용하고, 두 번째 층에 AND게이트를 적용해보자.
그리고 첫 번째 출력을 $s_1, s_2$라 하자. 

| $x_1$ | $x_2$ | $s_1$ (NAND) | $s_2$ (OR) | $y$ (AND) |
| ----- | ----- | ------------ | ---------- | --------- |
| 0     | 0     | 1            | 0          | 0         |
| 1     | 0     | 1            | 1          | 1         |
| 0     | 1     | 1            | 1          | 1         |
| 1     | 1     | 0            | 1          | 0         |

층 두개를 만드니 출력 $y$가 XOR문제를 만족한다.







이러한 문제를 풀기위해서 한 개의 층이 아니라 층을 두 개, 세 개, 여러개를 놓아 비선형적으로 분리되는 데이터에도 학습이 가능하도록 **다층 퍼셉트론(multi-layer perceptron)**을 고안했다.

층을 더욱 많이 만들면서 입력층, 출력층 사이에 은닉층이 여러개 있는 신경망을 만들었는데 이를 **심층 신경망(Deep Neural Network, DNN)** 또는 **딥러닝**이라고 한다.











자료

- programmer.ink <a href="https://programmer.ink/think/machine-learning-perceptron-implements-and-or-nand-gate-and-xor-gate.html">이미지 출처</a>

- 밑바닥 부터 시작하는 딥러닝 1권